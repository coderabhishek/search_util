In the minimum-cost multicommodity-flow problem, we are given directed graph G = (V, E)
in which each edge (u, v) E has a nonnegative capacity c(u, v) ≥ = 0 and a cost a(u, v). As
in the multicommodity-flow problem, we are given k different commodities, K1, K2, ..., Kk,
where commodity i is specified by the triple Ki = (si, ti, di). We define the flow fi for
commodity i and the aggregate flow f (u, v) on edge (u, v) as in the multicommodity-flow
problem. A feasible flow is one in which the aggregate flow on each edge (u, v) is no more
than the capacity of edge (u, v). The cost of a flow is Σu, v V a(u, v) f(u, v), and the goal is to
find the feasible flow of minimum cost. Express this problem as a linear program.

29.3 The simplex algorithm
The simplex algorithm is the classical method for solving linear programs. In contrast to most
of the other algorithms in this book, its running time is not polynomial in the worst case. It
does yield insight into linear programs, however, and is often remarkably fast in practice.
In addition to having a geometric interpretation, described earlier in this chapter, the simplex
algorithm bears some similarity to Gaussian elimination, discussed in Section 28.3. Gaussian
elimination begins with a system of linear equalities whose solution is unknown. In each
iteration, we rewrite this system in a equivalent form that has some additional structure. After
some number of iterations, we have rewritten the system so that the solution is simple to
obtain. The simplex algorithm proceeds in a similar manner, and we can view it as Gaussian
elimination for inequalities.
We now describe the main idea behind an iteration of the simplex algorithm. Associated with
each iteration will be a "basic solution" that is easily obtained from the slack form of the
linear program: set each nonbasic variable to 0, and compute the values of the basic variables
from the equality constraints. A basic solution will always correspond to a vertex of the
simplex. Algebraically, an iteration converts one slack form into an equivalent slack form.
The objective value of the associated basic feasible solution will be no less than that at the
previous iteration (and usually greater). To achieve this increase in the objective value, we
choose a nonbasic variable such that if we were to increase that variable's value from 0, then
the objective value would increase too. The amount by which we can increase the variable is
limited by the other constraints. In particular, we raise it until some basic variable becomes 0.
We then rewrite the slack form, exchanging the roles of that basic variable and the chosen
nonbasic variable. Although we have used a particular setting of the variables to guide the
algorithm, and we shall use it in our proofs, the algorithm does not explicitly maintain this
solution. It simply rewrites the linear program until the optimal solution becomes "obvious."
An example of the simplex algorithm
We begin with an extended example. Consider the following linear program in standard form:
(29.56)
subject to
(29.57)
(29.58)
(29.59)
(29.60)

