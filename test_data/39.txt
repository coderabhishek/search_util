The expression ⌈x⌉ denotes the least integer greater than or equal to x, and ⌊x⌋ denotes the
greatest integer less than or equal to x. These notations are defined in Chapter 3. The easiest

[7]

way to verify that setting q to ⌊( p + r)/2⌋ yields subarrays A[p

q] and A[q + 1

r] of sizes

⌈n/2⌉ and ⌊n/2⌋, respectively, is to examine the four cases that arise depending on whether
each of p and r is odd or even.

[8]

It is unlikely that the same constant exactly represents both the time to solve problems of
size 1 and the time per array element of the divide and combine steps. We can get around this
problem by letting c be the larger of these times and understanding that our recurrence gives
an upper bound on the running time, or by letting c be the lesser of these times and
understanding that our recurrence gives a lower bound on the running time. Both bounds will
be on the order of n lg n and, taken together, give a Θ(n lg n) running time.

Chapter notes
In 1968, Knuth published the first of three volumes with the general title The Art of Computer
Programming [182, 183, 185]. The first volume ushered in the modern study of computer
algorithms with a focus on the analysis of running time, and the full series remains an
engaging and worthwhile reference for many of the topics presented here. According to
Knuth, the word "algorithm" is derived from the name "al-Khowârizmî," a ninth-century
Persian mathematician.
Aho, Hopcroft, and Ullman [5] advocated the asymptotic analysis of algorithms as a means of
comparing relative performance. They also popularized the use of recurrence relations to
describe the running times of recursive algorithms.
Knuth [185] provides an encyclopedic treatment of many sorting algorithms. His comparison
of sorting algorithms (page 381) includes exact step-counting analyses, like the one we
performed here for insertion sort. Knuth's discussion of insertion sort encompasses several
variations of the algorithm. The most important of these is Shell's sort, introduced by D. L.
Shell, which uses insertion sort on periodic subsequences of the input to produce a faster
sorting algorithm.
Merge sort is also described by Knuth. He mentions that a mechanical collator capable of
merging two decks of punched cards in a single pass was invented in 1938. J. von Neumann,
one of the pioneers of computer science, apparently wrote a program for merge sort on the
EDVAC computer in 1945.
The early history of proving programs correct is described by Gries [133], who credits P.
Naur with the first article in this field. Gries attributes loop invariants to R. W. Floyd. The
textbook by Mitchell [222] describes more recent progress in proving programs correct.

Chapter 3: Growth of Functions
Overview

