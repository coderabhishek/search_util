for i = 0, 1, . . . , n - 1. At the first and last knots, we assume that
these assumptions make f(x) a natural cubic spline.

and

b. Use the continuity constraints on the second derivative to show that for i = 1, 2, . . . , n
- 1,
(28.35)
c. Show that
(28.36)
(28.37)
d. Rewrite equations (28.35)-(28.37) as a matrix equation involving the vector D = D0,
D1, . . . , Dn of unknowns. What attributes does the matrix in your equation have?
e. Argue that a set of n + 1 point-value pairs can be interpolated with a natural cubic
spline in O(n) time (see Problem 28-1).
f. Show how to determine a natural cubic spline that interpolates a set of n + 1 points (xi,
yi) satisfying x0 < x1 < · · · < xn, even when xi is not necessarily equal to i. What matrix
equation must be solved, and how quickly does your algorithm run?

Chapter notes
There are many excellent texts available that describe numerical and scientific computation in
much greater detail than we have room for here. The following are especially readable:
George and Liu [113], Golub and Van Loan [125], Press, Flannery, Teukolsky, and Vetterling
[248], [249], and Strang [285], [286].
Golub and Van Loan [125] discuss numerical stability. They show why det(A) is not
necessarily a good indicator of the stability of a matrix A, proposing instead to use A ∞ A1
. They also address the question of how to compute this value
∞, where
-1
without actually computing A .
The publication of Strassen's algorithm in 1969 [287] caused much excitement. Before then, it
was hard to imagine that the naive algorithm could be improved upon. The asymptotic upper
bound on the difficulty of matrix multiplication has since been considerably improved. The
most asymptotically efficient algorithm for multiplying n × n matrices to date, due to
Coppersmith and Winograd [70], has a running time of O(n2.376). The graphical presentation
of Strassen's algorithm is due to Paterson [238].
Gaussian elimination, upon which the LU and LUP decompositions are based, was the first
systematic method for solving linear systems of equations. It was also one of the earliest
numerical algorithms. Although it was known earlier, its discovery is commonly attributed to
C. F. Gauss (1777–1855). In his famous paper [287], Strassen also showed that an n × n
matrix can be inverted in O(nlg 7) time. Winograd [317] originally proved that matrix
multiplication is no harder than matrix inversion, and the converse is due to Aho, Hopcroft,
and Ullman [5].

