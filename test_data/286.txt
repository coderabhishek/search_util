Step 1: The structure of an optimal parenthesization
Our first step in the dynamic-programming paradigm is to find the optimal substructure and
then use it to construct an optimal solution to the problem from optimal solutions to
subproblems. For the matrix-chain multiplication problem, we can perform this step as
follows. For convenience, let us adopt the notation Ai j, where i ≤ j, for the matrix that results
from evaluating the product Ai Ai+1 Aj. Observe that if the problem is nontrivial, i.e., i < j, then
any parenthesization of the product Ai Ai+1 Aj must split the product between Ak and Ak+1 for
some integer k in the range i ≤ k < j. That is, for some value of k, we first compute the
matrices Ai k and Ak+1 j and then multiply them together to produce the final product Ai j. The
cost of this parenthesization is thus the cost of computing the matrix Ai k, plus the cost of
computing Ak+1 j, plus the cost of multiplying them together.
The optimal substructure of this problem is as follows. Suppose that an optimal
parenthesization of Ai Ai+1 Aj splits the product between Ak and Ak+1. Then the parenthesization
of the "prefix" subchain Ai Ai+1 Ak within this optimal parenthesization of Ai Ai+1 Aj must be an
optimal parenthesization of Ai Ai+1 Ak. Why? If there were a less costly way to parenthesize Ai
Ai+1 Ak, substituting that parenthesization in the optimal parenthesization of Ai Ai+1 Aj would
produce another parenthesization of Ai Ai+1 Aj whose cost was lower than the optimum: a
contradiction. A similar observation holds for the parenthesization of the subchain Ak+1 Ak+2 Aj
in the optimal parenthesization of Ai Ai+1 Aj: it must be an optimal parenthesization of Ak+1
Ak+2 Aj.
Now we use our optimal substructure to show that we can construct an optimal solution to the
problem from optimal solutions to subproblems. We have seen that any solution to a
nontrivial instance of the matrix-chain multiplication problem requires us to split the product,
and that any optimal solution contains within it optimal solutions to subproblem instances.
Thus, we can build an optimal solution to an instance of the matrix-chain multiplication
problem by splitting the problem into two subproblems (optimally parenthesizing Ai Ai+1 Ak
and Ak+1 Ak+2 Aj), finding optimal solutions to subproblem instances, and then combining these
optimal subproblem solutions. We must ensure that when we search for the correct place to
split the product, we have considered all possible places so that we are sure of having
examined the optimal one.
Step 2: A recursive solution
Next, we define the cost of an optimal solution recursively in terms of the optimal solutions to
subproblems. For the matrix-chain multiplication problem, we pick as our subproblems the
problems of determining the minimum cost of a parenthesization of Ai Ai+1 Aj for 1 ≤ i ≤ j ≤ n.
Let m[i, j] be the minimum number of scalar multiplications needed to compute the matrix
Ai j; for the full problem, the cost of a cheapest way to compute A1 n would thus be m[1, n].
We can define m[i, j] recursively as follows. If i = j, the problem is trivial; the chain consists
of just one matrix Ai i = Ai, so that no scalar multiplications are necessary to compute the
product. Thus, m[i, i] = 0 for i = 1, 2, ..., n. To compute m[i, j] when i < j, we take advantage
of the structure of an optimal solution from step 1. Let us assume that the optimal
parenthesization splits the product Ai Ai+1 Aj between Ak and Ak+1, where i ≤ k < j. Then, m[i, j]
is equal to the minimum cost for computing the subproducts Ai k and Ak+1 j, plus the cost of
multiplying these two matrices together. Recalling that each matrix Ai is pi-1 × pi, we see that

